{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part D: Train and Evaluate various models\n",
    "\n",
    "### Appraoch:\n",
    "    1) Training following model on extracted features (Reasons based on intutions)\n",
    "        - Logistic Regressions\n",
    "        - SVM \n",
    "        - XGBoost\n",
    "            \n",
    "    2) Experiment on constrained dataset \n",
    "        - Only on generated dataset for \"Hello world\" without any image augumentation\n",
    "    \n",
    "    3) Evaluation of model from ^ on augumented dataset\n",
    "        - Why? Check if the model has generalised for the characterstics of the font\n",
    "    \n",
    "    4) Experiment with augumented dataset\n",
    "        - Why? Check performance of the model trained on augumented dataset\n",
    "        \n",
    "        \n",
    "### Conclusion:\n",
    "    1) LR gave 94% precision on the limited distribution of \"Hello World text\"\n",
    "    2) While SVM was 90% precision but was also able to capture font from other phrases\n",
    "    3) For the augumented data - LR was 83% precise\n",
    "    \n",
    "    \n",
    "### Other experiments that can be performed:\n",
    "    1) Hyperparameter optimisations for XGB, SVM\n",
    "    2) Currently, I maxpooled RESNET features from last layer to flatten \n",
    "       but we can use 3D features with CNNs\n",
    "    3) We can train a good capacity fully connected NN (1-3 layers) with softmax \n",
    "       to capture complex patterns\n",
    "    4) Add data for more phrases to build more training data\n",
    "    5) Maybe try with resizing image with padding on top and bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train_file.csv\")\n",
    "df_test = pd.read_csv(\"test_file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Roboto           2016\n",
       "OpenSans         1680\n",
       "Arimo            1680\n",
       "Ubuntu           1344\n",
       "Oswald           1176\n",
       "DancingScript     840\n",
       "PTSerif           672\n",
       "NotoSans          672\n",
       "FredokaOne        168\n",
       "PatuaOne          168\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Roboto           864\n",
       "Arimo            720\n",
       "OpenSans         720\n",
       "Ubuntu           576\n",
       "Oswald           504\n",
       "DancingScript    360\n",
       "NotoSans         288\n",
       "PTSerif          288\n",
       "PatuaOne          72\n",
       "FredokaOne        72\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_extracted_features(filepaths):\n",
    "    \"\"\"\n",
    "    \n",
    "    Load extracted features file for all the given filepaths\n",
    "    \"\"\"\n",
    "    \n",
    "    image_vectors = []\n",
    "    for filepath in filepaths:\n",
    "        \n",
    "        load_filepath = 'data/extracted_features/{}'.format(filepath.split('/')[-1].replace('.png', 'pkl'))\n",
    "        \n",
    "        with open(load_filepath, 'rb') as load_filepath:\n",
    "            image_vectors.append(pickle.load(load_filepath))\n",
    "            \n",
    "    return image_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Experiment on constrained dataset (as in the problem statement)\n",
    "- Only \"Hello World\" text images\n",
    "- Image with no image augumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter original train-test file\n",
    "df_train_contrained = df_train[\n",
    "    (df_train['text'] == 'Hello-World')\n",
    "    & (df_train['agumentation_type'].isnull())\n",
    "].reset_index()\n",
    "\n",
    "df_test_contrained = df_test[\n",
    "    (df_test['text'] == 'Hello-World')\n",
    "    & (df_test['agumentation_type'].isnull())\n",
    "].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1320, 2048), (540, 2048), 1320, 540)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make training and testing objects\n",
    "X_train = np.array(load_extracted_features(list(df_train_contrained['file_path_preprocessed'])))\n",
    "X_test = np.array(load_extracted_features(list(df_test_contrained['file_path_preprocessed'])))\n",
    "\n",
    "y_train = list(df_train_contrained['label'])\n",
    "y_test = list(df_test_contrained['label'])\n",
    "\n",
    "X_train.shape, X_test.shape, len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vedvasu/.virtualenvs/squadai/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/vedvasu/.virtualenvs/squadai/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.98 s, sys: 3.19 ms, total: 2.98 s\n",
      "Wall time: 2.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_lr = LogisticRegression(random_state=2, class_weight='balanced')\n",
    "clf_lr = clf_lr.fit(X_train, y_train)\n",
    "clf_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Arimo       1.00      0.99      0.99        82\n",
      "DancingScript       1.00      1.00      1.00        47\n",
      "   FredokaOne       1.00      1.00      1.00         6\n",
      "     NotoSans       0.54      0.64      0.58        33\n",
      "     OpenSans       0.85      0.77      0.81        92\n",
      "       Oswald       1.00      1.00      1.00        73\n",
      "      PTSerif       1.00      1.00      1.00        32\n",
      "     PatuaOne       1.00      1.00      1.00        14\n",
      "       Roboto       0.97      1.00      0.99       111\n",
      "       Ubuntu       1.00      1.00      1.00        50\n",
      "\n",
      "     accuracy                           0.94       540\n",
      "    macro avg       0.94      0.94      0.94       540\n",
      " weighted avg       0.94      0.94      0.94       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = clf_lr.predict_proba(X_test)\n",
    "y_pred = list(pd.DataFrame(scores, columns=clf_lr.classes_).idxmax(axis=1))\n",
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vedvasu/.virtualenvs/squadai/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.9 s, sys: 313 ms, total: 30.2 s\n",
      "Wall time: 29.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "clf_svm = SVC(C=0.1, probability=True)\n",
    "clf_svm = clf_svm.fit(X_train, y_train)\n",
    "clf_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Arimo       1.00      0.98      0.99        82\n",
      "DancingScript       1.00      1.00      1.00        47\n",
      "   FredokaOne       1.00      0.83      0.91         6\n",
      "     NotoSans       0.43      0.45      0.44        33\n",
      "     OpenSans       0.70      0.78      0.74        92\n",
      "       Oswald       1.00      1.00      1.00        73\n",
      "      PTSerif       0.97      0.97      0.97        32\n",
      "     PatuaOne       1.00      0.86      0.92        14\n",
      "       Roboto       0.99      0.92      0.95       111\n",
      "       Ubuntu       1.00      1.00      1.00        50\n",
      "\n",
      "     accuracy                           0.90       540\n",
      "    macro avg       0.91      0.88      0.89       540\n",
      " weighted avg       0.91      0.90      0.90       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = clf_svm.predict_proba(X_test)\n",
    "y_pred = list(pd.DataFrame(scores, columns=clf_svm.classes_).idxmax(axis=1))\n",
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 59s, sys: 119 ms, total: 3min 59s\n",
      "Wall time: 31.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "clf_xgb = XGBClassifier(n_jobs= -1, random_state=2, max_depth=4, objective='multi:softmax')\n",
    "clf_xgb = clf_xgb.fit(X_train, y_train)\n",
    "clf_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Arimo       0.99      0.99      0.99        82\n",
      "DancingScript       1.00      1.00      1.00        47\n",
      "   FredokaOne       1.00      1.00      1.00         6\n",
      "     NotoSans       0.52      0.48      0.50        33\n",
      "     OpenSans       0.79      0.79      0.79        92\n",
      "       Oswald       1.00      0.97      0.99        73\n",
      "      PTSerif       0.91      1.00      0.96        32\n",
      "     PatuaOne       1.00      0.79      0.88        14\n",
      "       Roboto       0.96      0.99      0.97       111\n",
      "       Ubuntu       1.00      1.00      1.00        50\n",
      "\n",
      "     accuracy                           0.92       540\n",
      "    macro avg       0.92      0.90      0.91       540\n",
      " weighted avg       0.92      0.92      0.92       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = clf_xgb.predict_proba(X_test)\n",
    "y_pred = list(pd.DataFrame(scores, columns=clf_xgb.classes_).idxmax(axis=1))\n",
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Evaluate on augumented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11160, 2048), 11160)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter original train-test file\n",
    "df_augumented = pd.concat([\n",
    "    df_train[~df_train['agumentation_type'].isnull()].reset_index(),\n",
    "    df_test[~df_test['agumentation_type'].isnull()].reset_index()\n",
    "]).reset_index(drop=True)\n",
    "    \n",
    "X_test_augumented = np.array(load_extracted_features(list(df_augumented['file_path_preprocessed'])))\n",
    "y_test_augumented = list(df_augumented['label'])\n",
    "\n",
    "X_test_augumented.shape, len(y_test_augumented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Arimo       0.48      0.19      0.27      1800\n",
      "DancingScript       0.62      0.38      0.48       900\n",
      "   FredokaOne       0.50      0.21      0.29       180\n",
      "     NotoSans       0.08      0.11      0.10       720\n",
      "     OpenSans       0.20      0.30      0.24      1800\n",
      "       Oswald       0.56      0.26      0.36      1260\n",
      "      PTSerif       0.61      0.43      0.51       720\n",
      "     PatuaOne       0.71      0.09      0.17       180\n",
      "       Roboto       0.42      0.40      0.41      2160\n",
      "       Ubuntu       0.24      0.49      0.32      1440\n",
      "\n",
      "     accuracy                           0.32     11160\n",
      "    macro avg       0.44      0.29      0.31     11160\n",
      " weighted avg       0.40      0.32      0.33     11160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = clf_lr.predict_proba(X_test_augumented)\n",
    "y_pred = list(pd.DataFrame(scores, columns=clf_lr.classes_).idxmax(axis=1))\n",
    "print (classification_report(y_test_augumented, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Arimo       0.96      0.03      0.06      1800\n",
      "DancingScript       1.00      0.02      0.04       900\n",
      "   FredokaOne       1.00      0.01      0.02       180\n",
      "     NotoSans       1.00      0.00      0.01       720\n",
      "     OpenSans       0.16      0.99      0.28      1800\n",
      "       Oswald       1.00      0.01      0.03      1260\n",
      "      PTSerif       1.00      0.06      0.12       720\n",
      "     PatuaOne       0.00      0.00      0.00       180\n",
      "       Roboto       0.86      0.03      0.05      2160\n",
      "       Ubuntu       0.77      0.07      0.12      1440\n",
      "\n",
      "     accuracy                           0.19     11160\n",
      "    macro avg       0.78      0.12      0.07     11160\n",
      " weighted avg       0.79      0.19      0.10     11160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vedvasu/.virtualenvs/squadai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "scores = clf_svm.predict_proba(X_test_augumented)\n",
    "y_pred = list(pd.DataFrame(scores, columns=clf_svm.classes_).idxmax(axis=1))\n",
    "print (classification_report(y_test_augumented, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Arimo       0.36      0.19      0.25      1800\n",
      "DancingScript       0.61      0.35      0.44       900\n",
      "   FredokaOne       0.54      0.08      0.14       180\n",
      "     NotoSans       0.23      0.01      0.02       720\n",
      "     OpenSans       0.21      0.22      0.22      1800\n",
      "       Oswald       0.22      0.70      0.34      1260\n",
      "      PTSerif       0.57      0.42      0.48       720\n",
      "     PatuaOne       0.06      0.06      0.06       180\n",
      "       Roboto       0.32      0.33      0.32      2160\n",
      "       Ubuntu       0.37      0.21      0.27      1440\n",
      "\n",
      "     accuracy                           0.29     11160\n",
      "    macro avg       0.35      0.26      0.25     11160\n",
      " weighted avg       0.34      0.29      0.28     11160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = clf_xgb.predict_proba(X_test_augumented)\n",
    "y_pred = list(pd.DataFrame(scores, columns=clf_xgb.classes_).idxmax(axis=1))\n",
    "print (classification_report(y_test_augumented, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Train model on whole dataset (original + augumented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10416, 2048), (4464, 2048), 10416, 4464)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make training and testing objects\n",
    "X_train = np.array(load_extracted_features(list(df_train['file_path_preprocessed'])))\n",
    "X_test = np.array(load_extracted_features(list(df_test['file_path_preprocessed'])))\n",
    "\n",
    "y_train = list(df_train['label'])\n",
    "y_test = list(df_test['label'])\n",
    "\n",
    "X_train.shape, X_test.shape, len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vedvasu/.virtualenvs/squadai/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/vedvasu/.virtualenvs/squadai/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 5s, sys: 87 ms, total: 2min 5s\n",
      "Wall time: 2min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_lr = LogisticRegression(random_state=2, class_weight='balanced')\n",
    "clf_lr = clf_lr.fit(X_train, y_train)\n",
    "clf_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Arimo       0.87      0.88      0.87       720\n",
      "DancingScript       0.98      0.99      0.99       360\n",
      "   FredokaOne       0.94      0.69      0.80        72\n",
      "     NotoSans       0.43      0.47      0.45       288\n",
      "     OpenSans       0.65      0.67      0.66       720\n",
      "       Oswald       0.99      0.99      0.99       504\n",
      "      PTSerif       0.97      0.94      0.96       288\n",
      "     PatuaOne       0.92      0.93      0.92        72\n",
      "       Roboto       0.80      0.81      0.81       864\n",
      "       Ubuntu       0.88      0.84      0.86       576\n",
      "\n",
      "     accuracy                           0.82      4464\n",
      "    macro avg       0.84      0.82      0.83      4464\n",
      " weighted avg       0.83      0.82      0.82      4464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = clf_lr.predict_proba(X_test)\n",
    "y_pred = list(pd.DataFrame(scores, columns=clf_lr.classes_).idxmax(axis=1))\n",
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vedvasu/.virtualenvs/squadai/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38min 21s, sys: 101 ms, total: 38min 21s\n",
      "Wall time: 38min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "clf_svm = SVC(probability=True)\n",
    "clf_svm = clf_svm.fit(X_train, y_train)\n",
    "clf_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Arimo       0.81      0.84      0.83       720\n",
      "DancingScript       0.99      1.00      0.99       360\n",
      "   FredokaOne       0.73      0.64      0.68        72\n",
      "     NotoSans       0.52      0.30      0.38       288\n",
      "     OpenSans       0.61      0.74      0.67       720\n",
      "       Oswald       0.97      0.97      0.97       504\n",
      "      PTSerif       0.95      0.90      0.92       288\n",
      "     PatuaOne       0.76      0.78      0.77        72\n",
      "       Roboto       0.80      0.80      0.80       864\n",
      "       Ubuntu       0.85      0.81      0.83       576\n",
      "\n",
      "     accuracy                           0.80      4464\n",
      "    macro avg       0.80      0.78      0.78      4464\n",
      " weighted avg       0.80      0.80      0.80      4464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = clf_svm.predict_proba(X_test)\n",
    "y_pred = list(pd.DataFrame(scores, columns=clf_svm.classes_).idxmax(axis=1))\n",
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44min 55s, sys: 2.06 s, total: 44min 57s\n",
      "Wall time: 5min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "clf_xgb = XGBClassifier(n_jobs= -1, random_state=2, max_depth=4, objective='multi:softmax')\n",
    "clf_xgb = clf_xgb.fit(X_train, y_train)\n",
    "clf_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Arimo       0.69      0.84      0.76       720\n",
      "DancingScript       0.98      1.00      0.99       360\n",
      "   FredokaOne       1.00      0.51      0.68        72\n",
      "     NotoSans       0.62      0.17      0.26       288\n",
      "     OpenSans       0.63      0.67      0.65       720\n",
      "       Oswald       0.96      0.94      0.95       504\n",
      "      PTSerif       0.93      0.88      0.90       288\n",
      "     PatuaOne       1.00      0.54      0.70        72\n",
      "       Roboto       0.70      0.79      0.74       864\n",
      "       Ubuntu       0.77      0.74      0.76       576\n",
      "\n",
      "     accuracy                           0.76      4464\n",
      "    macro avg       0.83      0.71      0.74      4464\n",
      " weighted avg       0.77      0.76      0.75      4464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = clf_xgb.predict_proba(X_test)\n",
    "y_pred = list(pd.DataFrame(scores, columns=clf_xgb.classes_).idxmax(axis=1))\n",
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
