{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part D: Train and Evaluate various models\n",
    "\n",
    "### Appraoch:\n",
    "    1) Training following model on extracted features (Reasons based on intutions)\n",
    "        - Logistic Regressions\n",
    "        - SVM \n",
    "        - XGBoost\n",
    "            \n",
    "    2) Experiment on constrained dataset \n",
    "        - Only on generated dataset for \"Hello world\" without any image augumentation\n",
    "    \n",
    "    3) Evaluation of model from ^ on augumented dataset\n",
    "        - Why? Check if the model has generalised for the characterstics of the font\n",
    "    \n",
    "    4) Experiment with augumented dataset\n",
    "        - Why? Check performance of the model trained on augumented dataset\n",
    "        \n",
    "        \n",
    "### Conclusion:\n",
    "    1) LR gave 94% precision on the limited distribution of \"Hello World text\"\n",
    "    2) While SVM was 90% precision but was also able to capture font from other phrases\n",
    "    3) For the augumented data - LR was 83% precise\n",
    "    \n",
    "    \n",
    "### Other experiments that can be performed:\n",
    "    1) Hyperparameter optimisations for XGB, SVM\n",
    "    2) Currently, I maxpooled RESNET features from last layer to flatten \n",
    "       but we can use 3D features with CNNs\n",
    "    3) We can train a good capacity fully connected NN (1-3 layers) with softmax \n",
    "       to capture complex patterns\n",
    "    4) Add data for more phrases to build more training data\n",
    "    5) Maybe try with resizing image with padding on top and bottom\n",
    "    6) Experiment with other features extractors trained on Imagenet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train_file.csv\")\n",
    "df_test = pd.read_csv(\"test_file.csv\")\n",
    "\n",
    "os.makedirs('models',  exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Roboto           3024\n",
       "Arimo            2520\n",
       "OpenSans         2520\n",
       "Ubuntu           2016\n",
       "Oswald           1764\n",
       "DancingScript    1260\n",
       "PTSerif          1008\n",
       "NotoSans         1008\n",
       "PatuaOne          252\n",
       "FredokaOne        252\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Roboto           1296\n",
       "OpenSans         1080\n",
       "Arimo            1080\n",
       "Ubuntu            864\n",
       "Oswald            756\n",
       "DancingScript     540\n",
       "NotoSans          432\n",
       "PTSerif           432\n",
       "PatuaOne          108\n",
       "FredokaOne        108\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_extracted_features(filepaths):\n",
    "    \"\"\"\n",
    "    \n",
    "    Load extracted features file for all the given filepaths\n",
    "    \"\"\"\n",
    "    \n",
    "    image_vectors = []\n",
    "    for filepath in filepaths:\n",
    "        \n",
    "        load_filepath = 'data/extracted_features/{}'.format(filepath.split('/')[-1].replace('.png', 'pkl'))\n",
    "        \n",
    "        with open(load_filepath, 'rb') as load_filepath:\n",
    "            image_vectors.append(pickle.load(load_filepath))\n",
    "            \n",
    "    return image_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Experiment on constrained dataset (as in the problem statement)\n",
    "- Only \"Hello, World!\", \"HELLO, WORLD!\" text images\n",
    "- Image with no image augumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter original train-test file\n",
    "df_train_contrained = df_train[\n",
    "    (df_train['text'].isin(['Hello,-World!', 'HELLO,-WORLD!']))\n",
    "    & (df_train['agumentation_type'].isnull())\n",
    "].reset_index()\n",
    "\n",
    "df_test_contrained = df_test[\n",
    "    (df_test['text'].isin(['Hello,-World!', 'HELLO,-WORLD!']))\n",
    "    & (df_test['agumentation_type'].isnull())\n",
    "].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2627, 2048), (1093, 2048), 2627, 1093)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make training and testing objects\n",
    "X_train = np.array(load_extracted_features(list(df_train_contrained['file_path_preprocessed'])))\n",
    "X_test = np.array(load_extracted_features(list(df_test_contrained['file_path_preprocessed'])))\n",
    "\n",
    "y_train = list(df_train_contrained['label'])\n",
    "y_test = list(df_test_contrained['label'])\n",
    "\n",
    "X_train.shape, X_test.shape, len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vedvasu/.virtualenvs/squadai/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/vedvasu/.virtualenvs/squadai/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.1 s, sys: 15.2 ms, total: 7.12 s\n",
      "Wall time: 7.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_lr = LogisticRegression(random_state=2, class_weight='balanced')\n",
    "clf_lr = clf_lr.fit(X_train, y_train)\n",
    "clf_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Arimo       0.99      0.99      0.99       183\n",
      "DancingScript       1.00      1.00      1.00        82\n",
      "   FredokaOne       1.00      1.00      1.00        19\n",
      "     NotoSans       0.70      0.80      0.75        75\n",
      "     OpenSans       0.90      0.85      0.88       177\n",
      "       Oswald       1.00      1.00      1.00       121\n",
      "      PTSerif       1.00      1.00      1.00        65\n",
      "     PatuaOne       1.00      1.00      1.00        17\n",
      "       Roboto       0.99      0.98      0.99       221\n",
      "       Ubuntu       1.00      1.00      1.00       133\n",
      "\n",
      "     accuracy                           0.96      1093\n",
      "    macro avg       0.96      0.96      0.96      1093\n",
      " weighted avg       0.96      0.96      0.96      1093\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = clf_lr.predict_proba(X_test)\n",
    "y_pred = list(pd.DataFrame(scores, columns=clf_lr.classes_).idxmax(axis=1))\n",
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/lr_weights.pkl', 'wb') as save_filepath:\n",
    "    pickle.dump(clf_lr, save_filepath, protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vedvasu/.virtualenvs/squadai/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 11s, sys: 17 ms, total: 2min 11s\n",
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "clf_svm = SVC(C=0.1, probability=True)\n",
    "clf_svm = clf_svm.fit(X_train, y_train)\n",
    "clf_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Arimo       0.92      0.90      0.91       183\n",
      "DancingScript       1.00      1.00      1.00        82\n",
      "   FredokaOne       1.00      0.89      0.94        19\n",
      "     NotoSans       0.73      0.61      0.67        75\n",
      "     OpenSans       0.72      0.86      0.79       177\n",
      "       Oswald       1.00      1.00      1.00       121\n",
      "      PTSerif       1.00      0.97      0.98        65\n",
      "     PatuaOne       1.00      0.88      0.94        17\n",
      "       Roboto       0.90      0.86      0.88       221\n",
      "       Ubuntu       0.95      0.93      0.94       133\n",
      "\n",
      "     accuracy                           0.89      1093\n",
      "    macro avg       0.92      0.89      0.90      1093\n",
      " weighted avg       0.90      0.89      0.89      1093\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = clf_svm.predict_proba(X_test)\n",
    "y_pred = list(pd.DataFrame(scores, columns=clf_svm.classes_).idxmax(axis=1))\n",
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/svm_weights.pkl', 'wb') as save_filepath:\n",
    "    pickle.dump(clf_svm, save_filepath, protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 30s, sys: 331 ms, total: 10min 31s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "clf_xgb = XGBClassifier(n_jobs= -1, random_state=2, max_depth=4, objective='multi:softmax')\n",
    "clf_xgb = clf_xgb.fit(X_train, y_train)\n",
    "clf_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Arimo       0.99      0.98      0.99       183\n",
      "DancingScript       1.00      1.00      1.00        82\n",
      "   FredokaOne       1.00      0.79      0.88        19\n",
      "     NotoSans       0.83      0.60      0.70        75\n",
      "     OpenSans       0.83      0.94      0.88       177\n",
      "       Oswald       1.00      1.00      1.00       121\n",
      "      PTSerif       0.97      1.00      0.98        65\n",
      "     PatuaOne       1.00      0.88      0.94        17\n",
      "       Roboto       0.97      0.99      0.98       221\n",
      "       Ubuntu       0.97      0.98      0.98       133\n",
      "\n",
      "     accuracy                           0.95      1093\n",
      "    macro avg       0.96      0.92      0.93      1093\n",
      " weighted avg       0.95      0.95      0.95      1093\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = clf_xgb.predict_proba(X_test)\n",
    "y_pred = list(pd.DataFrame(scores, columns=clf_xgb.classes_).idxmax(axis=1))\n",
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/xgb_weights.pkl', 'wb') as save_filepath:\n",
    "    pickle.dump(clf_xgb, save_filepath, protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Evaluate on augumented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16740, 2048), 16740)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter original train-test file\n",
    "df_augumented = pd.concat([\n",
    "    df_train[~df_train['agumentation_type'].isnull()].reset_index(),\n",
    "    df_test[~df_test['agumentation_type'].isnull()].reset_index()\n",
    "]).reset_index(drop=True)\n",
    "    \n",
    "X_test_augumented = np.array(load_extracted_features(list(df_augumented['file_path_preprocessed'])))\n",
    "y_test_augumented = list(df_augumented['label'])\n",
    "\n",
    "X_test_augumented.shape, len(y_test_augumented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Arimo       0.35      0.38      0.36      2700\n",
      "DancingScript       0.86      0.44      0.58      1350\n",
      "   FredokaOne       0.10      0.46      0.17       270\n",
      "     NotoSans       0.13      0.21      0.16      1080\n",
      "     OpenSans       0.40      0.08      0.13      2700\n",
      "       Oswald       0.86      0.46      0.60      1890\n",
      "      PTSerif       0.48      0.41      0.44      1080\n",
      "     PatuaOne       0.31      0.30      0.30       270\n",
      "       Roboto       0.46      0.24      0.31      3240\n",
      "       Ubuntu       0.21      0.55      0.30      2160\n",
      "\n",
      "     accuracy                           0.33     16740\n",
      "    macro avg       0.42      0.35      0.34     16740\n",
      " weighted avg       0.45      0.33      0.34     16740\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = clf_lr.predict_proba(X_test_augumented)\n",
    "y_pred = list(pd.DataFrame(scores, columns=clf_lr.classes_).idxmax(axis=1))\n",
    "print (classification_report(y_test_augumented, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Arimo       0.80      0.07      0.13      2700\n",
      "DancingScript       1.00      0.11      0.20      1350\n",
      "   FredokaOne       1.00      0.06      0.11       270\n",
      "     NotoSans       0.64      0.03      0.06      1080\n",
      "     OpenSans       0.18      0.97      0.30      2700\n",
      "       Oswald       1.00      0.08      0.15      1890\n",
      "      PTSerif       0.83      0.17      0.28      1080\n",
      "     PatuaOne       1.00      0.04      0.07       270\n",
      "       Roboto       0.73      0.15      0.25      3240\n",
      "       Ubuntu       0.69      0.10      0.18      2160\n",
      "\n",
      "     accuracy                           0.24     16740\n",
      "    macro avg       0.79      0.18      0.17     16740\n",
      " weighted avg       0.71      0.24      0.20     16740\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = clf_svm.predict_proba(X_test_augumented)\n",
    "y_pred = list(pd.DataFrame(scores, columns=clf_svm.classes_).idxmax(axis=1))\n",
    "print (classification_report(y_test_augumented, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Arimo       0.32      0.37      0.34      2700\n",
      "DancingScript       0.84      0.30      0.44      1350\n",
      "   FredokaOne       0.34      0.19      0.25       270\n",
      "     NotoSans       0.23      0.03      0.06      1080\n",
      "     OpenSans       0.35      0.13      0.19      2700\n",
      "       Oswald       0.60      0.25      0.35      1890\n",
      "      PTSerif       0.28      0.41      0.33      1080\n",
      "     PatuaOne       0.30      0.10      0.15       270\n",
      "       Roboto       0.31      0.45      0.37      3240\n",
      "       Ubuntu       0.21      0.44      0.28      2160\n",
      "\n",
      "     accuracy                           0.31     16740\n",
      "    macro avg       0.38      0.27      0.28     16740\n",
      " weighted avg       0.37      0.31      0.30     16740\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = clf_xgb.predict_proba(X_test_augumented)\n",
    "y_pred = list(pd.DataFrame(scores, columns=clf_xgb.classes_).idxmax(axis=1))\n",
    "print (classification_report(y_test_augumented, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Train model on whole dataset (original + augumented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15624, 2048), (6696, 2048), 15624, 6696)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make training and testing objects\n",
    "X_train = np.array(load_extracted_features(list(df_train['file_path_preprocessed'])))\n",
    "X_test = np.array(load_extracted_features(list(df_test['file_path_preprocessed'])))\n",
    "\n",
    "y_train = list(df_train['label'])\n",
    "y_test = list(df_test['label'])\n",
    "\n",
    "X_train.shape, X_test.shape, len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vedvasu/.virtualenvs/squadai/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/vedvasu/.virtualenvs/squadai/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 47s, sys: 69.6 ms, total: 4min 47s\n",
      "Wall time: 4min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_lr = LogisticRegression(random_state=2, class_weight='balanced')\n",
    "clf_lr = clf_lr.fit(X_train, y_train)\n",
    "clf_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Arimo       0.83      0.85      0.84      1080\n",
      "DancingScript       0.99      0.99      0.99       540\n",
      "   FredokaOne       0.92      0.81      0.86       108\n",
      "     NotoSans       0.41      0.46      0.43       432\n",
      "     OpenSans       0.66      0.66      0.66      1080\n",
      "       Oswald       0.99      0.98      0.99       756\n",
      "      PTSerif       0.97      0.95      0.96       432\n",
      "     PatuaOne       0.96      0.86      0.91       108\n",
      "       Roboto       0.80      0.79      0.80      1296\n",
      "       Ubuntu       0.84      0.81      0.82       864\n",
      "\n",
      "     accuracy                           0.81      6696\n",
      "    macro avg       0.84      0.82      0.82      6696\n",
      " weighted avg       0.81      0.81      0.81      6696\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = clf_lr.predict_proba(X_test)\n",
    "y_pred = list(pd.DataFrame(scores, columns=clf_lr.classes_).idxmax(axis=1))\n",
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/lr_augumented_weights.pkl', 'wb') as save_filepath:\n",
    "    pickle.dump(clf_lr, save_filepath, protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vedvasu/.virtualenvs/squadai/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 28min 22s, sys: 277 ms, total: 1h 28min 23s\n",
      "Wall time: 1h 28min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "clf_svm = SVC(probability=True)\n",
    "clf_svm = clf_svm.fit(X_train, y_train)\n",
    "clf_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Arimo       0.83      0.85      0.84      1080\n",
      "DancingScript       1.00      1.00      1.00       540\n",
      "   FredokaOne       0.84      0.73      0.78       108\n",
      "     NotoSans       0.58      0.38      0.46       432\n",
      "     OpenSans       0.67      0.73      0.70      1080\n",
      "       Oswald       0.98      0.97      0.97       756\n",
      "      PTSerif       0.97      0.93      0.95       432\n",
      "     PatuaOne       0.76      0.83      0.80       108\n",
      "       Roboto       0.75      0.82      0.79      1296\n",
      "       Ubuntu       0.87      0.78      0.82       864\n",
      "\n",
      "     accuracy                           0.81      6696\n",
      "    macro avg       0.82      0.80      0.81      6696\n",
      " weighted avg       0.81      0.81      0.81      6696\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = clf_svm.predict_proba(X_test)\n",
    "y_pred = list(pd.DataFrame(scores, columns=clf_svm.classes_).idxmax(axis=1))\n",
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/svm_augumented_weights.pkl', 'wb') as save_filepath:\n",
    "    pickle.dump(clf_svm, save_filepath, protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 6min 17s, sys: 368 ms, total: 1h 6min 17s\n",
      "Wall time: 8min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "clf_xgb = XGBClassifier(n_jobs= -1, random_state=2, max_depth=4, objective='multi:softmax')\n",
    "clf_xgb = clf_xgb.fit(X_train, y_train)\n",
    "clf_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Arimo       0.67      0.83      0.75      1080\n",
      "DancingScript       0.98      0.99      0.98       540\n",
      "   FredokaOne       1.00      0.63      0.77       108\n",
      "     NotoSans       0.73      0.18      0.29       432\n",
      "     OpenSans       0.64      0.67      0.65      1080\n",
      "       Oswald       0.96      0.96      0.96       756\n",
      "      PTSerif       0.93      0.89      0.91       432\n",
      "     PatuaOne       0.97      0.57      0.72       108\n",
      "       Roboto       0.68      0.78      0.73      1296\n",
      "       Ubuntu       0.76      0.71      0.73       864\n",
      "\n",
      "     accuracy                           0.76      6696\n",
      "    macro avg       0.83      0.72      0.75      6696\n",
      " weighted avg       0.77      0.76      0.75      6696\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = clf_xgb.predict_proba(X_test)\n",
    "y_pred = list(pd.DataFrame(scores, columns=clf_xgb.classes_).idxmax(axis=1))\n",
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/xgb_augumented_weights.pkl', 'wb') as save_filepath:\n",
    "    pickle.dump(clf_xgb, save_filepath, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
