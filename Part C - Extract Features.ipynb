{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C: Extract Features\n",
    "\n",
    "### Appraoch:\n",
    "    1) RESNET features are extracted for each generated and preprocessed image in train and test file\n",
    "    2) The extracted features are saved to avoid extracting again (in case its required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.applications import resnet50\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train_file.csv\")\n",
    "df_test = pd.read_csv(\"test_file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Roboto           3024\n",
       "OpenSans         2520\n",
       "Arimo            2520\n",
       "Ubuntu           2016\n",
       "Oswald           1764\n",
       "DancingScript    1260\n",
       "NotoSans         1008\n",
       "PTSerif          1008\n",
       "FredokaOne        252\n",
       "PatuaOne          252\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Roboto           1296\n",
       "OpenSans         1080\n",
       "Arimo            1080\n",
       "Ubuntu            864\n",
       "Oswald            756\n",
       "DancingScript     540\n",
       "NotoSans          432\n",
       "PTSerif           432\n",
       "FredokaOne        108\n",
       "PatuaOne          108\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_restnet_features(filepaths):\n",
    "    \"\"\"\n",
    "    For each image in the filepaths list, extract and return RESNET50 feature\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Load all images\n",
    "    image_vectors = []\n",
    "    for filepath in filepaths:\n",
    "        with Image.open(filepath) as image_vector:\n",
    "            image_vectors.append(image_vector.copy())\n",
    "\n",
    "    # Preprocessing for Resnet50\n",
    "    image_arrays = [image.img_to_array(vector) for vector in image_vectors]\n",
    "    processed_arrays = resnet50.preprocess_input(np.array(image_arrays))\n",
    "\n",
    "    # Load pretrained model (Max pooling is used as the original features are 7 x 7 x 2048)\n",
    "    model = resnet50.ResNet50(weights='imagenet', include_top=False, pooling='max')\n",
    "    features = model.predict(processed_arrays)\n",
    "\n",
    "    # Flatten features\n",
    "    features = [x.reshape(1, 2048)[0] for x in features]\n",
    "    \n",
    "    # Save all features\n",
    "    for filepath, feature in zip(filepaths, features):\n",
    "        save_filepath = 'data/extracted_features/{}'.format(filepath.split('/')[-1].replace('.png', 'pkl'))\n",
    "        with open(save_filepath, 'wb') as save_filepath:\n",
    "            pickle.dump(feature, save_filepath, protocol=4)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def extract_features(filepaths, chunk_size=1000):\n",
    "    \"\"\"\n",
    "    Run function \"save_restnet_features\" in chunks \n",
    "     - To tackle memory constraints by avoid loading all images/ features in the memory at once\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    os.makedirs('data/extracted_features',  exist_ok=True)\n",
    "    \n",
    "    for start in range(0, len(filepaths), chunk_size):\n",
    "        \n",
    "        print (\"Extracting Features for batch:\", start/chunk_size)\n",
    "        save_restnet_features(filepaths[start:start + chunk_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Features for batch: 0.0\n",
      "Extracting Features for batch: 1.0\n",
      "Extracting Features for batch: 2.0\n",
      "Extracting Features for batch: 3.0\n",
      "Extracting Features for batch: 4.0\n",
      "Extracting Features for batch: 5.0\n",
      "Extracting Features for batch: 6.0\n",
      "Extracting Features for batch: 7.0\n",
      "Extracting Features for batch: 8.0\n",
      "Extracting Features for batch: 9.0\n",
      "Extracting Features for batch: 10.0\n",
      "Extracting Features for batch: 11.0\n",
      "Extracting Features for batch: 12.0\n",
      "Extracting Features for batch: 13.0\n",
      "Extracting Features for batch: 14.0\n",
      "Extracting Features for batch: 15.0\n",
      "CPU times: user 1h 37min 36s, sys: 4min 38s, total: 1h 42min 15s\n",
      "Wall time: 14min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "extract_features(list(df_train['file_path_preprocessed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Features for batch: 0.0\n",
      "Extracting Features for batch: 1.0\n",
      "Extracting Features for batch: 2.0\n",
      "Extracting Features for batch: 3.0\n",
      "Extracting Features for batch: 4.0\n",
      "Extracting Features for batch: 5.0\n",
      "Extracting Features for batch: 6.0\n",
      "CPU times: user 41min 53s, sys: 2min 6s, total: 44min\n",
      "Wall time: 6min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "extract_features(list(df_test['file_path_preprocessed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
